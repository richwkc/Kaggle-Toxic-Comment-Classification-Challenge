{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec then RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1919960022472173355\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import *\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, TimeDistributed, Dropout, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras_train_helper import tfauc\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras_train_helper import rotateTensorboardLogs\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_train_helper import PrintAucCallback\n",
    "\n",
    "tensorBoardCallback = TensorBoard(log_dir=\"./tb-logs\")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and setting up preprocessing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "train: (127656, 8), test: (31915, 8), allData: (159571, 8), contestTest: (153164, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test, allData, contestTest = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting sentences...\n",
      "Splitting sentences...\n",
      "Loading w2i and i2w dictionaries...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "maxSeqLength = 250\n",
    "\n",
    "splitter = SentenceSplitter(\"comment_text\")\n",
    "allWords = pd.concat([splitter.transform(allData), splitter.transform(contestTest)])\n",
    "w2i = Word2Int(allWords)\n",
    "zeroPadder = ZeroPadder(maxSeqLength)\n",
    "\n",
    "preparationPipeline = Pipeline(steps=[\n",
    "    (\"split\", splitter),\n",
    "    (\"w2i\", w2i),\n",
    "    (\"zeroPadding\", zeroPadder) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation\n",
    "import importlib\n",
    "importlib.reload(data_preparation)\n",
    "from data_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec dictionary...\n",
      "CPU times: user 2.17 s, sys: 76 ms, total: 2.25 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = Word2Vec(\"webcrawl\", w2i.i2w, seed=4324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix, i2v = w2v.embeddingMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmUnits = 100\n",
    "numClasses = 2\n",
    "batchSize = 1024\n",
    "\n",
    "def defineModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(\n",
    "        embeddingMatrix.shape[0],\n",
    "        embeddingMatrix.shape[1],\n",
    "        weights=[embeddingMatrix],\n",
    "        input_length=maxSeqLength,\n",
    "        trainable=False))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(lstmUnits), name=\"LSTM\"))\n",
    "\n",
    "    model.add(Dropout(.2, name=\"dropout\"))\n",
    "\n",
    "    model.add(Dense(\n",
    "        2, \n",
    "        activation=\"softmax\", \n",
    "        name=\"softmax_output\"))\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[tfauc])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, trainDataset, testDataset, label, epochs, fast=False):\n",
    "    print(\"Training model for target variable: {}\".format(label))\n",
    "    \n",
    "    tf.set_random_seed(43245)\n",
    "    np.random.seed(453252)\n",
    "    \n",
    "    labelizer = Labelizer(label)\n",
    "    oversampler = Oversampler(label)\n",
    "    \n",
    "    trainOversampled = oversampler.transform(trainDataset)\n",
    "\n",
    "    trainSentences = preparationPipeline.transform(trainOversampled)\n",
    "    trainLabels = labelizer.transform(trainOversampled)\n",
    "    testSentences = preparationPipeline.transform(testDataset)\n",
    "    testLabels = labelizer.transform(testDataset)\n",
    "\n",
    "    printAucCallback = PrintAucCallback(\n",
    "        [trainSentences, trainLabels], \n",
    "        [testSentences, testLabels], \n",
    "        4* batchSize, \n",
    "        printFrequency=0.1)\n",
    "\n",
    "    model.fit(\n",
    "        trainSentences, \n",
    "        trainLabels, \n",
    "        nb_epoch=epochs, \n",
    "        batch_size=batchSize,\n",
    "        callbacks=[] if fast else [tensorBoardCallback, printAucCallback])\n",
    "    \n",
    "    return model, printAucCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = defineModel()\n",
    "_, printAucCallback = fitModel(model, train, test, \"toxic\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "contestModels = [\n",
    "    fitModel(defineModel(), allData, test, label, epochs, fast=True)\n",
    "    for (label, epochs)\n",
    "    in [(\"toxic\", 2), (\"severe_toxic\", 2), (\"obscene\", 1), (\"threat\", 1), (\"insult\", 1), (\"identity_hate\", 1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "contestPredictionProbabilities = {category: model.predict(preparationPipeline.transform(contestTest)) for (category, model) in zip(categories, contestModels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffledResult = pd.DataFrame(dict(\n",
    "    [(\"id\", contestTest.id)] \n",
    "    + [(name, preds[:, 1]) for (name, preds) in contestPredictionProbabilities.items()]))\n",
    "\n",
    "result = suffledResult[[\"id\"] + categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.107428</td>\n",
       "      <td>0.086610</td>\n",
       "      <td>0.179781</td>\n",
       "      <td>0.043975</td>\n",
       "      <td>0.104099</td>\n",
       "      <td>0.086608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.147077</td>\n",
       "      <td>0.124943</td>\n",
       "      <td>0.256728</td>\n",
       "      <td>0.045869</td>\n",
       "      <td>0.097912</td>\n",
       "      <td>0.125053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.144134</td>\n",
       "      <td>0.122432</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.073960</td>\n",
       "      <td>0.156137</td>\n",
       "      <td>0.122611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.076373</td>\n",
       "      <td>0.186833</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.076566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.105768</td>\n",
       "      <td>0.083794</td>\n",
       "      <td>0.182512</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.066183</td>\n",
       "      <td>0.083650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.107428      0.086610  0.179781  0.043975  0.104099   \n",
       "1  0000247867823ef7  0.147077      0.124943  0.256728  0.045869  0.097912   \n",
       "2  00013b17ad220c46  0.144134      0.122432  0.231361  0.073960  0.156137   \n",
       "3  00017563c3f7919a  0.094946      0.076373  0.186833  0.022637  0.050725   \n",
       "4  00017695ad8997eb  0.105768      0.083794  0.182512  0.037039  0.066183   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.086608  \n",
       "1       0.125053  \n",
       "2       0.122611  \n",
       "3       0.076566  \n",
       "4       0.083650  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./submissions/w2v-then-rnn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([value for key, value in printAucCallback.listOfAucs])\n",
    "\n",
    "plt.ylabel(\"Area under ROC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from evaluate_predictions import evaluatePredictions\n",
    "\n",
    "predictions = model.predict(testSentences, batch_size=batchSize)\n",
    "binaryPredictions = np.where(predictions[:, 1] > 0.5, 1, 0)\n",
    "labels = testLabels[:, 1]\n",
    "\n",
    "evaluatePredictions(pd.Series(labels), binaryPredictions, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
