{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec then RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7715724662805126216\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import *\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, TimeDistributed, Dropout, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras_train_helper import tfauc\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras_train_helper import rotateTensorboardLogs\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_train_helper import PrintAucCallback\n",
    "\n",
    "tensorBoardCallback = TensorBoard(log_dir=\"./tb-logs\")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and setting up preprocessing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "train: (127656, 8), test: (31915, 8), allData: (159571, 8), contestTest: (153164, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test, allData, contestTest = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting sentences...\n",
      "Splitting sentences...\n",
      "Loading w2i and i2w dictionaries...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "maxSeqLength = 250\n",
    "\n",
    "splitter = SentenceSplitter(\"comment_text\")\n",
    "allWords = pd.concat([splitter.transform(allData), splitter.transform(contestTest)])\n",
    "w2i = Word2Int(allWords)\n",
    "zeroPadder = ZeroPadder(maxSeqLength)\n",
    "\n",
    "preparationPipeline = Pipeline(steps=[\n",
    "    (\"split\", splitter),\n",
    "    (\"w2i\", w2i),\n",
    "    (\"zeroPadding\", zeroPadder) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation\n",
    "import importlib\n",
    "importlib.reload(data_preparation)\n",
    "from data_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec dictionary...\n",
      "CPU times: user 2.05 s, sys: 12 ms, total: 2.06 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = Word2Vec(50, w2i.i2w, seed=4324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix, i2v = w2v.embeddingMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmUnits = [100]\n",
    "numClasses = 2\n",
    "batchSize = 1024\n",
    "\n",
    "def defineModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(\n",
    "        embeddingMatrix.shape[0],\n",
    "        embeddingMatrix.shape[1],\n",
    "        weights=[embeddingMatrix],\n",
    "        input_length=maxSeqLength,\n",
    "        trainable=False))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(lstmUnits[0]), name=\"LSTM\"))\n",
    "\n",
    "    model.add(Dropout(.2, name=\"dropout\"))\n",
    "\n",
    "    model.add(Dense(\n",
    "        2, \n",
    "        activation=\"softmax\", \n",
    "        name=\"softmax_output\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[tfauc])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, trainDataset, testDataset, label, epochs, fast=False):\n",
    "    print(\"Training model for target variable: {}\".format(label))\n",
    "    \n",
    "    tf.set_random_seed(43245)\n",
    "    np.random.seed(453252)\n",
    "    \n",
    "    labelizer = Labelizer(label)\n",
    "    oversampler = Oversampler(label)\n",
    "    \n",
    "    trainOversampled = oversampler.transform(trainDataset)\n",
    "\n",
    "    trainSentences = preparationPipeline.transform(trainOversampled)\n",
    "    trainLabels = labelizer.transform(trainOversampled)\n",
    "    testSentences = preparationPipeline.transform(testDataset)\n",
    "    testLabels = labelizer.transform(testDataset)\n",
    "\n",
    "    printAucCallback = PrintAucCallback(testSentences, testLabels, allTestDataPerEpochs=1)\n",
    "    if fast:\n",
    "        callbacks = []\n",
    "    else:\n",
    "        callbacks = [tensorBoardCallback, printAucCallback]\n",
    "    \n",
    "    model.fit(\n",
    "        trainSentences, \n",
    "        trainLabels, \n",
    "        nb_epoch=epochs, \n",
    "        batch_size=batchSize,\n",
    "        callbacks=callbacks)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: toxic\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.7953 - tfauc: 0.1988\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3712 - tfauc: 0.7146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fa7b3b18320>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = defineModel()\n",
    "fitModel(model, train[:1000], test[:1000], \"toxic\", 2, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: toxic\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - all-test-data-auc: 0.4678\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.7953 - tfauc: 0.1988\n",
      "Epoch 2/2\n",
      " - all-test-data-auc: 0.5375\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3712 - tfauc: 0.7146\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: severe_toxic\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Epoch 1/2\n",
      " - all-test-data-auc: 0.4059\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.8047 - tfauc: 0.1636\n",
      "Epoch 2/2\n",
      " - all-test-data-auc: 0.5278\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2527 - tfauc: 0.7690\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: obscene\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Epoch 1/1\n",
      " - all-test-data-auc: 0.4275\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.8017 - tfauc: 0.1758\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: threat\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Epoch 1/3\n",
      " - all-test-data-auc: 0.8759\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.5824 - tfauc: 0.9255\n",
      "Epoch 2/3\n",
      " - all-test-data-auc: 0.8468\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1564 - tfauc: 0.9795\n",
      "Epoch 3/3\n",
      " - all-test-data-auc: 0.8178\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0828 - tfauc: 0.9898\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: insult\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Epoch 1/2\n",
      " - all-test-data-auc: 0.5018\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.5406 - tfauc: 0.9348\n",
      "Epoch 2/2\n",
      " - all-test-data-auc: 0.5512\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2479 - tfauc: 0.9455\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 250, 50)           19255800  \n",
      "_________________________________________________________________\n",
      "LSTM (Bidirectional)         (None, 200)               120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,377,002\n",
      "Trainable params: 121,202\n",
      "Non-trainable params: 19,255,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Building model for target variable: identity_hate\n",
      "Oversampling...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Epoch 1/2\n",
      " - all-test-data-auc: 0.4724\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.8045 - tfauc: 0.1647\n",
      "Epoch 2/2\n",
      " - all-test-data-auc: 0.5667\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2545 - tfauc: 0.7683\n"
     ]
    }
   ],
   "source": [
    "contestModels = [\n",
    "    fitModel(defineModel(), train, test, label, epochs) \n",
    "    for label, epochs \n",
    "    in [(\"toxic\", 2), (\"severe_toxic\", 2), (\"obscene\", 1), (\"threat\", 3), (\"insult\", 2), (\"identity_hate\", 2)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n",
      "Splitting sentences...\n",
      "Converting words to integers...\n",
      "Zero-padding...\n"
     ]
    }
   ],
   "source": [
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "contestPredictionProbabilities = {category: model.predict(preparationPipeline.transform(contestTest[:1000])) for (category, model) in zip(categories, contestModels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffledResult = pd.DataFrame(dict(\n",
    "    [(\"id\", contestTest[:1000].id)] \n",
    "    + [(name, preds[:, 1]) for (name, preds) in contestPredictionProbabilities.items()]))\n",
    "\n",
    "result = suffledResult[[\"id\"] + categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.107428</td>\n",
       "      <td>0.086610</td>\n",
       "      <td>0.179781</td>\n",
       "      <td>0.043975</td>\n",
       "      <td>0.104099</td>\n",
       "      <td>0.086608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.147077</td>\n",
       "      <td>0.124943</td>\n",
       "      <td>0.256728</td>\n",
       "      <td>0.045869</td>\n",
       "      <td>0.097912</td>\n",
       "      <td>0.125053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.144134</td>\n",
       "      <td>0.122432</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.073960</td>\n",
       "      <td>0.156137</td>\n",
       "      <td>0.122611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.076373</td>\n",
       "      <td>0.186833</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.076566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.105768</td>\n",
       "      <td>0.083794</td>\n",
       "      <td>0.182512</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.066183</td>\n",
       "      <td>0.083650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.107428      0.086610  0.179781  0.043975  0.104099   \n",
       "1  0000247867823ef7  0.147077      0.124943  0.256728  0.045869  0.097912   \n",
       "2  00013b17ad220c46  0.144134      0.122432  0.231361  0.073960  0.156137   \n",
       "3  00017563c3f7919a  0.094946      0.076373  0.186833  0.022637  0.050725   \n",
       "4  00017695ad8997eb  0.105768      0.083794  0.182512  0.037039  0.066183   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.086608  \n",
       "1       0.125053  \n",
       "2       0.122611  \n",
       "3       0.076566  \n",
       "4       0.083650  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./submissions/w2v-then-rnn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([value for key, value in printAucCallback.listOfAucs])\n",
    "\n",
    "plt.ylabel(\"Area under ROC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from evaluate_predictions import evaluatePredictions\n",
    "\n",
    "predictions = model.predict(testSentences, batch_size=batchSize)\n",
    "binaryPredictions = np.where(predictions[:, 1] > 0.5, 1, 0)\n",
    "labels = testLabels[:, 1]\n",
    "\n",
    "evaluatePredictions(pd.Series(labels), binaryPredictions, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
