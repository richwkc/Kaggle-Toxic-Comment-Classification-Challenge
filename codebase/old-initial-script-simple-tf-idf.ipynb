{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "The idea is use the simple approch of tf-idf using panda and sklearn. If training is slow, launch a large instance in aws to run an extensive grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of model on split train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=543553)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIndex, testIndex = list(split.split(data, data.toxic))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.iloc[trainIndex], data.iloc[testIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentences(dataset):\n",
    "    return (dataset.comment_text\n",
    "    .str.replace(\"[^A-Za-z\\s]\", \"\")\n",
    "    .str.lower()\n",
    "    .str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 152 ms, total: 3.4 s\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitTrain = splitSentences(train)\n",
    "splitTest = splitSentences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.4 s, sys: 5.79 s, total: 58.2 s\n",
      "Wall time: 58.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    \"/home/mariosk/Documents/common-ml-models/GoogleNews-vectors-negative300.bin\", \n",
    "    binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 364 ms, sys: 28 ms, total: 392 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocabulary = set(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 s, sys: 84 ms, total: 25.9 s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def wordsToVector(words):\n",
    "    allowedWords = [word for word in words if word in vocabulary]\n",
    "    \n",
    "    return model.wv[allowedWords if allowedWords else [\"hello\"]].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainFeatures = np.array(splitTrain.apply(wordsToVector).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.48 s, sys: 0 ns, total: 6.48 s\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testFeatures = np.array(splitTest.apply(wordsToVector).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer().fit(train.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = tfidf.transform(train.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "testFeatures = tfidf.transform(test.comment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(dataset, categories):\n",
    "    return {category: dataset[category] for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def getModels(datasetFeatures, labelColumns):\n",
    "    return {category: LogisticRegression().fit(datasetFeatures, column) \n",
    "            for (category, column) in labelColumns.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(models, datasetFeatures):\n",
    "    return {category: model.predict(datasetFeatures) for (category, model) in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbabilityPredictions(models, datasetFeatures):\n",
    "    return {category: model.predict_proba(datasetFeatures) for (category, model) in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "trainLabels = getLabels(train, categories)\n",
    "\n",
    "models = getModels(trainFeatures, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = getPredictions(models, testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionProbabilities = getProbabilityPredictions(models, testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels = getLabels(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def cramersV(contmat):\n",
    "    '''Function to calculate cramers'V and \n",
    "    associated p-value using contingency matrix'''\n",
    "    nrow, ncol = contmat.shape\n",
    "    nobs = np.sum(contmat.sum())\n",
    "    chi2, pvalue, dof, expected = stats.chi2_contingency(contmat)\n",
    "    n = np.min([nrow - 1, ncol - 1])\n",
    "    v = np.sqrt(chi2 / (nobs * n))\n",
    "    return np.array([v, pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(datasetLabels, predictions, predictionProbabilities):\n",
    "    return { category: {\n",
    "            \"Confusion Matrix\": confusion_matrix(datasetLabels[category], predictions[category]), \n",
    "            \"Relativized Confusion Matrix\": confusion_matrix(datasetLabels[category], predictions[category]) / float(len(predictions[category])),\n",
    "            \"F1 score\": round(f1_score(datasetLabels[category], predictions[category], pos_label=1.0), 3),\n",
    "            \"Logarithmic loss\": round(log_loss(datasetLabels[category], predictionProbabilities[category]), 4),\n",
    "            \"Cramer's V\": cramersV(confusion_matrix(datasetLabels[category], predictions[category]))}\n",
    "        for category in categories }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, log_loss\n",
    "\n",
    "metrics = getMetrics(testLabels, predictions, predictionProbabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(metrics):\n",
    "    for (category, metricValues) in metrics.items():\n",
    "        print(\"\")\n",
    "        print(\"Category: {}\".format(category))\n",
    "        print(\"-\"*50)\n",
    "        for (name, value) in metricValues.items():\n",
    "            print(name + \":\")\n",
    "            print(value)\n",
    "\n",
    "    print(\"-\"*50 + \"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    print(\"Average\")\n",
    "    print(\"-\"*50)\n",
    "    for metric in list(metrics.items())[0][1].keys():\n",
    "        print(metric + \":\")\n",
    "        print(sum([value[metric] for value in metrics.values()]) / float(len(metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print metrics for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: toxic\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[28690   166]\n",
      " [ 1219  1840]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.899  0.0052]\n",
      " [0.0382 0.0577]]\n",
      "F1 score:\n",
      "0.727\n",
      "Logarithmic loss:\n",
      "0.117\n",
      "Cramer's V:\n",
      "[0.7224 0.    ]\n",
      "\n",
      "Category: severe_toxic\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[31532    68]\n",
      " [  229    86]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.988  0.0021]\n",
      " [0.0072 0.0027]]\n",
      "F1 score:\n",
      "0.367\n",
      "Logarithmic loss:\n",
      "0.0274\n",
      "Cramer's V:\n",
      "[0.3841 0.    ]\n",
      "\n",
      "Category: obscene\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[30139    88]\n",
      " [  664  1024]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9444 0.0028]\n",
      " [0.0208 0.0321]]\n",
      "F1 score:\n",
      "0.731\n",
      "Logarithmic loss:\n",
      "0.0679\n",
      "Cramer's V:\n",
      "[0.7365 0.    ]\n",
      "\n",
      "Category: threat\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[31803     8]\n",
      " [   98     6]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9965 0.0003]\n",
      " [0.0031 0.0002]]\n",
      "F1 score:\n",
      "0.102\n",
      "Logarithmic loss:\n",
      "0.0129\n",
      "Cramer's V:\n",
      "[0.1432 0.    ]\n",
      "\n",
      "Category: insult\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[30153   158]\n",
      " [  811   793]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9448 0.005 ]\n",
      " [0.0254 0.0248]]\n",
      "F1 score:\n",
      "0.621\n",
      "Logarithmic loss:\n",
      "0.0831\n",
      "Cramer's V:\n",
      "[0.6281 0.    ]\n",
      "\n",
      "Category: identity_hate\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[31589    18]\n",
      " [  252    56]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9898 0.0006]\n",
      " [0.0079 0.0018]]\n",
      "F1 score:\n",
      "0.293\n",
      "Logarithmic loss:\n",
      "0.0301\n",
      "Cramer's V:\n",
      "[0.3651 0.    ]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[30651.        84.3333]\n",
      " [  545.5      634.1667]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9604 0.0026]\n",
      " [0.0171 0.0199]]\n",
      "F1 score:\n",
      "0.47350000000000003\n",
      "Logarithmic loss:\n",
      "0.0564\n",
      "Cramer's V:\n",
      "[0.4966 0.    ]\n"
     ]
    }
   ],
   "source": [
    "printMetrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print metrics for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: toxic\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[114962    459]\n",
      " [  4435   7800]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9006 0.0036]\n",
      " [0.0347 0.0611]]\n",
      "F1 score:\n",
      "0.761\n",
      "Logarithmic loss:\n",
      "0.1022\n",
      "Cramer's V:\n",
      "[0.7581 0.    ]\n",
      "\n",
      "Category: severe_toxic\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[126206    170]\n",
      " [   943    337]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9886 0.0013]\n",
      " [0.0074 0.0026]]\n",
      "F1 score:\n",
      "0.377\n",
      "Logarithmic loss:\n",
      "0.0235\n",
      "Cramer's V:\n",
      "[0.4143 0.    ]\n",
      "\n",
      "Category: obscene\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[120614    281]\n",
      " [  2386   4375]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9448 0.0022]\n",
      " [0.0187 0.0343]]\n",
      "F1 score:\n",
      "0.766\n",
      "Logarithmic loss:\n",
      "0.0574\n",
      "Cramer's V:\n",
      "[0.7702 0.    ]\n",
      "\n",
      "Category: threat\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[127267     15]\n",
      " [   318     56]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.997  0.0001]\n",
      " [0.0025 0.0004]]\n",
      "F1 score:\n",
      "0.252\n",
      "Logarithmic loss:\n",
      "0.0087\n",
      "Cramer's V:\n",
      "[0.3399 0.    ]\n",
      "\n",
      "Category: insult\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[120871    512]\n",
      " [  2820   3453]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9468 0.004 ]\n",
      " [0.0221 0.027 ]]\n",
      "F1 score:\n",
      "0.675\n",
      "Logarithmic loss:\n",
      "0.0681\n",
      "Cramer's V:\n",
      "[0.6805 0.    ]\n",
      "\n",
      "Category: identity_hate\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[126497     62]\n",
      " [   910    187]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9909 0.0005]\n",
      " [0.0071 0.0015]]\n",
      "F1 score:\n",
      "0.278\n",
      "Logarithmic loss:\n",
      "0.0232\n",
      "Cramer's V:\n",
      "[0.3546 0.    ]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Average\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[122736.1667    249.8333]\n",
      " [  1968.6667   2701.3333]]\n",
      "Relativized Confusion Matrix:\n",
      "[[0.9615 0.002 ]\n",
      " [0.0154 0.0212]]\n",
      "F1 score:\n",
      "0.5181666666666666\n",
      "Logarithmic loss:\n",
      "0.047183333333333334\n",
      "Cramer's V:\n",
      "[0.5529 0.    ]\n"
     ]
    }
   ],
   "source": [
    "printMetrics(getMetrics(\n",
    "    trainLabels, \n",
    "    getPredictions(models, trainFeatures), \n",
    "    getProbabilityPredictions(models, trainFeatures)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    return { category: round(model.predict_proba(tfidf.transform([sentence]))[0][1], 3) for (category, model) in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'identity_hate': 0.031,\n",
       " 'insult': 0.843,\n",
       " 'obscene': 0.995,\n",
       " 'severe_toxic': 0.441,\n",
       " 'threat': 0.005,\n",
       " 'toxic': 0.995}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"dick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all data and evaluate on the contest test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "contestTrain = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentTest = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "contestTfidf = TfidfVectorizer().fit(contestTrain.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "contestTrainFeatures = contestTfidf.transform(contestTrain.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "contestTestFeatures = contestTfidf.transform(contentTest.comment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "contestCategoryColumns = {category: contestTrain[category] for category in categories}\n",
    "\n",
    "contestModels = {category: LogisticRegression().fit(contestTrainFeatures, column) for (category, column) in contestCategoryColumns.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "contestPredictionProbabilities = {category: model.predict_proba(contestTestFeatures) for (category, model) in contestModels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffledResult = pd.DataFrame(dict(\n",
    "    [(\"id\", contentTest.id)] \n",
    "    + [(name, preds[:, 1]) for (name, preds) in contestPredictionProbabilities.items()]))\n",
    "\n",
    "result = suffledResult[[\"id\"] + categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.179390</td>\n",
       "      <td>0.994815</td>\n",
       "      <td>0.046207</td>\n",
       "      <td>0.961407</td>\n",
       "      <td>0.280959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.003058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.042410</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.023446</td>\n",
       "      <td>0.006136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.034391</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.003610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.998337      0.179390  0.994815  0.046207  0.961407   \n",
       "1  0000247867823ef7  0.006600      0.001563  0.003997  0.000433  0.005721   \n",
       "2  00013b17ad220c46  0.042410      0.006402  0.020804  0.001987  0.023446   \n",
       "3  00017563c3f7919a  0.003176      0.001637  0.003099  0.001038  0.003707   \n",
       "4  00017695ad8997eb  0.034391      0.004016  0.011180  0.001724  0.011583   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.280959  \n",
       "1       0.003058  \n",
       "2       0.006136  \n",
       "3       0.000930  \n",
       "4       0.003610  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./data/sample_submission.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./submissions/simple-tf-idf-without-exponents.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
