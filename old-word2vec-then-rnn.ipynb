{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec then RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "\n",
    "importDirectory = \"../state/data/preprocessed-train-test/\"\n",
    "\n",
    "train, test, data, contestTest = map(\n",
    "    lambda filename: pd.read_csv(path.join(importDirectory, filename)), \n",
    "    [\"train.csv\", \"test.csv\", \"all.csv\", \"contest-test.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (127656, 8), test: (31915, 8), all: (159571, 8), contestTest: (153164, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train: {}, test: {}, all: {}, contestTest: {}\".format(\n",
    "    train.shape, test.shape, data.shape, contestTest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentences(dataset):\n",
    "    return (dataset.comment_text\n",
    "    .str.replace(\"[^A-Za-z\\s]\", \"\")\n",
    "    .str.lower()\n",
    "    .str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 172 ms, total: 3.18 s\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitTrain = splitSentences(train)\n",
    "splitTest = splitSentences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentense lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    127656.000000\n",
       "mean         65.470616\n",
       "std          97.108352\n",
       "min           0.000000\n",
       "25%          16.000000\n",
       "50%          35.000000\n",
       "75%          73.000000\n",
       "max        1403.000000\n",
       "Name: comment_text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceLengths = splitTrain.apply(len)\n",
    "sentenceLengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b6f4c9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentenceLengths.plot.box()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wdcGLQZmfCjEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b469d9cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths.hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 508 ms, total: 25.3 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"../state/external-models/glove.6B/w2v.glove.6B.50.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDimensions = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 4 ms, total: 56 ms\n",
      "Wall time: 54.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocabulary = set(model.vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform sentences to sequences of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 17.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "# If possible, vectorize this transformation\n",
    "def wordsToVector(words):\n",
    "    allowedWords = [word for word in words if word in vocabulary]\n",
    "    leftWords = allowedWords if allowedWords else [\"hello\"]\n",
    "    \n",
    "    return np.array(list(map(model.word_vec, leftWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 452 ms, total: 17.9 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2vTrainFeatures = splitTrain.apply(wordsToVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.56 s, sys: 164 ms, total: 4.72 s\n",
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2vTestFeatures = splitTest.apply(wordsToVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(dataset, features, label): \n",
    "    multiples = int(dataset[dataset[label] == 0].shape[0] / dataset[dataset[label] == 1].shape[0])\n",
    "    \n",
    "    datasetPositive = dataset[dataset[label] == 1]\n",
    "    featuresPositive = features[datasetPositive.index.tolist()]\n",
    "    \n",
    "    datasetOversampled = pd.concat([dataset] + multiples * [datasetPositive]).reset_index() \n",
    "    featuresOversampled = pd.concat([features] + multiples * [featuresPositive]).reset_index().comment_text\n",
    "    \n",
    "    return datasetOversampled, featuresOversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOversampled, w2vTrainFeaturesOversampled = oversample(train, w2vTrainFeatures, \"toxic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to get batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is padding the words till position 250 with 0s the right approach?\n",
    "def padWithZeros(array):\n",
    "    fullArray = np.zeros([maxSeqLength, numDimensions])\n",
    "    fullArray[:min(array.shape[0], maxSeqLength), :] = array[:min(array.shape[0], maxSeqLength), :]\n",
    "    return fullArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always remember to reset the seed before using getTrainBatch\n",
    "np.random.seed(4324)\n",
    "\n",
    "# Check if vectorizing this one can improve performance\n",
    "def getBatch(dataset, features, size):\n",
    "    indices = np.random.randint(0, len(features), size)\n",
    "    \n",
    "    features = np.array(features[indices].apply(padWithZeros).tolist())\n",
    "    labels = (np\n",
    "        .array(dataset.toxic[indices]\n",
    "        .apply(\n",
    "            lambda label: np.array([0., 1.]) if label == 0 else np.array([1., 0.])).tolist()))\n",
    "    return features, labels\n",
    "\n",
    "def getTrainBatch(size):\n",
    "    return getBatch(trainOversampled, w2vTrainFeaturesOversampled, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMST with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesAndLabels(dataset, features, size):\n",
    "    features = np.array(features[:size].apply(padWithZeros).tolist())\n",
    "    labels = np.array(\n",
    "        dataset\n",
    "            .toxic[:size]\n",
    "            .apply(\n",
    "                lambda label: np.array([0., 1.]) if label == 0 else np.array([1., 0.])).tolist())\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 328 ms, sys: 104 ms, total: 432 ms\n",
      "Wall time: 432 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Beware, this will use ~40 GB of RAM\n",
    "trainFeatures, trainLabels = getFeaturesAndLabels(trainOversampled, w2vTrainFeaturesOversampled, trainOversampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "batchSize = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17596088703314465664\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(43245)\n",
    "np.random.seed(453252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 29,570\n",
      "Trainable params: 29,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(lstmUnits, dropout=0.2, recurrent_dropout=0.2, input_shape=trainFeatures.shape[1:]))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariosk/anaconda2/envs/ipykernel_py3/lib/python3.6/site-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 48s - loss: 0.3113 - acc: 0.9062\n",
      "Epoch 2/5\n",
      " - 46s - loss: 0.2956 - acc: 0.9070\n",
      "Epoch 3/5\n",
      " - 53s - loss: 0.2990 - acc: 0.9017\n",
      "Epoch 4/5\n",
      " - 54s - loss: 0.3160 - acc: 0.9032\n",
      "Epoch 5/5\n",
      " - 55s - loss: 0.3153 - acc: 0.9032\n",
      "CPU times: user 13min 9s, sys: 45.5 s, total: 13min 54s\n",
      "Wall time: 4min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b30ff0dd8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(trainFeatures, trainLabels, nb_epoch=5, batch_size=batchSize, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "batchSize = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses], name=\"labels\")\n",
    "data = tf.placeholder(tf.float32, [batchSize, maxSeqLength, numDimensions], name=\"data\")\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCellWithDropout = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCellWithDropout, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "auc = 1 - tf.metrics.auc(tf.argmax(labels, 1), tf.clip_by_value(prediction[:, 0], 0, 1), name=\"auc\")[1]\n",
    "acc = tf.metrics.accuracy(tf.argmax(labels, 1), tf.argmax(prediction, 1), name=\"accuracy\")[1]\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels), name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Area_under_roc', auc)\n",
    "tf.summary.scalar(\"Accuracy\", acc)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "saver = tf.train.Saver()\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "np.random.seed(4324)\n",
    "tf.set_random_seed(43245)\n",
    "\n",
    "epochs = 10\n",
    "samplesPerEpoch = int(trainOversampled.shape[0] / batchSize)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch #{}\".format(epoch))\n",
    "        for i in range(samplesPerEpoch):\n",
    "            nextBatch, nextBatchLabels = getTrainBatch(batchSize)\n",
    "            \n",
    "            sess.run(optimizer, {data: nextBatch, labels: nextBatchLabels})\n",
    "\n",
    "            #Save the network every 1,000 training iterations\n",
    "            iteration = epoch * samplesPerEpoch + i\n",
    "            \n",
    "            if (iteration % 1000 == 0 and iteration != 0):\n",
    "                save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=iteration)\n",
    "                print(\"saved to %s\" % save_path)\n",
    "                \n",
    "            #Write summary to Tensorboard\n",
    "            if (iteration % 100 == 0 and iteration != 0):\n",
    "                print(f\"Loss: {sess.run(loss, {data: nextBatch, labels: nextBatchLabels})}\")\n",
    "                print(f\"Acc: {sess.run(acc, {data: nextBatch, labels: nextBatchLabels})}\")\n",
    "                print(f\"Auc: {sess.run(auc, {data: nextBatch, labels: nextBatchLabels})}\")\n",
    "                summary = sess.run(merged, {data: nextBatch, labels: nextBatchLabels})\n",
    "                writer.add_summary(summary, iteration)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestBatch(size):\n",
    "    return getBatch(test, w2vTestFeatures, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "saver = tf.train.Saver()\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "preds = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, \"./models/pretrained_lstm.ckpt-74000\")\n",
    "    \n",
    "    for i in range(int(test.shape[0]/batchSize)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        nextBatch, nextBatchLabels = getTestBatch(batchSize)\n",
    "\n",
    "        preds.append((sess.run(prediction, {data: nextBatch}), nextBatchLabels[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd, labs = zip(*preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdProbVec = np.concatenate(prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdVec = np.where(prdProbVec[:, 0] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labsVec = np.concatenate(labs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "saver = tf.train.Saver()\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "logloss = []\n",
    "accuracy = []\n",
    "auroc = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, \"./models/pretrained_lstm.ckpt-74000\")\n",
    "    \n",
    "    for i in range(int(test.shape[0]/batchSize)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        nextBatch, nextBatchLabels = getTestBatch(batchSize)\n",
    "        logloss.append(sess.run(loss, {data: nextBatch, labels: nextBatchLabels}))\n",
    "        accuracy.append(sess.run(acc, {data: nextBatch, labels: nextBatchLabels}))\n",
    "        auroc.append(sess.run(auc, {data: nextBatch, labels: nextBatchLabels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lavg(l):\n",
    "    return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss: {lavg(logloss)}\")\n",
    "print(f\"Accuracy: {lavg(accuracy)}\")\n",
    "print(f\"AUC: {lavg(auroc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_predictions import evaluatePredictions\n",
    "\n",
    "evaluatePredictions(pd.Series(labsVec), prdVec, 1 - prdProbVec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}