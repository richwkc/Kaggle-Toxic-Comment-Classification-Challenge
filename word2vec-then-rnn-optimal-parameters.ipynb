{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec then RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "importDirectory = \"../state/data/preprocessed-train-test/\"\n",
    "\n",
    "train, test, data, contestTest = map(\n",
    "    lambda filename: pd.read_csv(path.join(importDirectory, filename)), \n",
    "    [\"train.csv\", \"test.csv\", \"all.csv\", \"contest-test.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (127656, 8), test: (31915, 8), all: (159571, 8), contestTest: (153164, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train: {}, test: {}, all: {}, contestTest: {}\".format(\n",
    "    train.shape, test.shape, data.shape, contestTest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentences(dataset):\n",
    "    return (dataset.comment_text\n",
    "    .str.replace(\"[^A-Za-z\\s]\", \"\")\n",
    "    .str.lower()\n",
    "    .str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.75 s, sys: 140 ms, total: 3.89 s\n",
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitTrain = splitSentences(train)\n",
    "splitTest = splitSentences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "allWords = set([word for sentence in pd.concat([splitTrain, splitTest]) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToInteger = { word: index for index, word in enumerate(allWords) }\n",
    "integerToWord = { index: word for index, word in enumerate(allWords) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "integerTrain = splitTrain.apply(lambda sentence: [wordToInteger[word] for word in sentence])\n",
    "integerTest = splitTest.apply(lambda sentence: [wordToInteger[word] for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Int2Vec embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDimensions = 50\n",
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 108 ms, total: 22.9 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "\n",
    "w2vModel = gensim.models.KeyedVectors.load_word2vec_format(\"../state/external-models/glove.6B/w2v.glove.6B.50.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "availableWords = set.intersection(allWords, set(w2vModel.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(432432)\n",
    "\n",
    "int2vec = {index: w2vModel.word_vec(word) \n",
    "             if word in availableWords \n",
    "             else np.random.normal(scale=.644, size=(numDimensions,))\n",
    "         for index, word in integerToWord.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix = np.array([vector for vector in int2vec.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(dataset, label): \n",
    "    multiples = int(dataset[dataset[label] == 0].shape[0] / dataset[dataset[label] == 1].shape[0])\n",
    "    \n",
    "    datasetPositive = dataset[dataset[label] == 1]\n",
    "    \n",
    "    return pd.concat([dataset] + multiples * [datasetPositive]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOversampled = oversample(train, \"toxic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero pad vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padArrayWithZeros(array):\n",
    "    fullArray = np.zeros(maxSeqLength)\n",
    "    fullArray[:min(array.shape[0], maxSeqLength)] = array[:min(array.shape[0], maxSeqLength)]\n",
    "    return fullArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareText(dataset):\n",
    "    return np.array(splitSentences(dataset)\n",
    "        .apply(lambda sentence: \n",
    "            padArrayWithZeros(np.array([\n",
    "                wordToInteger[word]\n",
    "                for word in sentence])))\n",
    "        .tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.38 s, sys: 248 ms, total: 9.62 s\n",
      "Wall time: 9.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainSentences = prepareText(trainOversampled)[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = np.array(trainOversampled\n",
    "    .toxic\n",
    "    .apply(lambda label: np.array([0, 1]) if label == 1 else np.array([1, 0]))\n",
    "    .tolist())[0:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMST RNN with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmUnits = [100]\n",
    "numClasses = 2\n",
    "batchSize = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8606361863497408411\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, TimeDistributed, Dropout, Embedding\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "     auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "     K.get_session().run(tf.local_variables_initializer())\n",
    "     return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 250, 50)           11198300  \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,258,902\n",
      "Trainable params: 60,602\n",
      "Non-trainable params: 11,198,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    embeddingMatrix.shape[0],\n",
    "    embeddingMatrix.shape[1],\n",
    "    weights=[embeddingMatrix],\n",
    "    input_length=maxSeqLength,\n",
    "    trainable=False))\n",
    "\n",
    "model.add(LSTM(\n",
    "    lstmUnits[0], \n",
    "    dropout=0.2, \n",
    "    recurrent_dropout=0.2,\n",
    "    name=\"LSTM\"))\n",
    "\n",
    "model.add(Dense(\n",
    "    2, \n",
    "    activation=\"softmax\", \n",
    "    name=\"softmax_output\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(43245)\n",
    "np.random.seed(453252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(\n",
    "    trainSentences, \n",
    "    trainLabels, \n",
    "    nb_epoch=5, \n",
    "    batch_size=batchSize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
